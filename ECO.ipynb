{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCV_lcck7tAZ"
   },
   "outputs": [],
   "source": [
    "#from comet_ml import Experiment\n",
    "#experiment = Experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ccpy4OkFMEM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFile\n",
    "from pickle import load, dump\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import subprocess\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.activation1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.activation2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(192)\n",
    "        self.activation3 = nn.ReLU(inplace=True)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.maxpool2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convA1 = nn.Conv2d(192, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnormA1 = nn.BatchNorm2d(64)\n",
    "        self.activationA1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.convB1 = nn.Conv2d(192, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnormB1 = nn.BatchNorm2d(64)\n",
    "        self.activationB1 = nn.ReLU(inplace=True)\n",
    "        self.convB2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnormB2 = nn.BatchNorm2d(64)\n",
    "        self.activationB2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.convC1 = nn.Conv2d(192, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnormC1 = nn.BatchNorm2d(64)\n",
    "        self.activationC1 = nn.ReLU(inplace=True)\n",
    "        self.convC2 = nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnormC2 = nn.BatchNorm2d(96)\n",
    "        self.activationC2 = nn.ReLU(inplace=True)\n",
    "        self.convC3 = nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnormC3 = nn.BatchNorm2d(96)\n",
    "        self.activationC3 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.avgpoolD1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.convD1 = nn.Conv2d(192, 32, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnormD1 = nn.BatchNorm2d(32)\n",
    "        self.activationD1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.convA1(x)\n",
    "        out1 = self.batchnormA1(out1)\n",
    "        out1 = self.activationA1(out1)\n",
    "        \n",
    "        out2 = self.convB1(x)\n",
    "        out2 = self.batchnormB1(out2)\n",
    "        out2 = self.activationB1(out2)\n",
    "        out2 = self.convB2(out2)\n",
    "        out2 = self.batchnormB2(out2)\n",
    "        out2 = self.activationB2(out2)\n",
    "        \n",
    "        out3 = self.convC1(x)\n",
    "        out3 = self.batchnormC1(out3)\n",
    "        out3 = self.activationC1(out3)\n",
    "        out3 = self.convC2(out3)\n",
    "        out3 = self.batchnormC2(out3)\n",
    "        out3 = self.activationC2(out3)\n",
    "        out3 = self.convC3(out3)\n",
    "        out3 = self.batchnormC3(out3)\n",
    "        out3 = self.activationC3(out3)\n",
    "        \n",
    "        out4 = self.avgpoolD1(x)\n",
    "        out4 = self.convD1(out4)\n",
    "        out4 = self.batchnormD1(out4)\n",
    "        out4 = self.activationD1(out4)\n",
    "        \n",
    "        out = [out1, out2, out3, out4]\n",
    "        return torch.cat(out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convA1 = nn.Conv2d(256, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnormA1 = nn.BatchNorm2d(64)\n",
    "        self.activationA1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.convB1 = nn.Conv2d(256, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnormB1 = nn.BatchNorm2d(64)\n",
    "        self.activationB1 = nn.ReLU(inplace=True)\n",
    "        self.convB2 = nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnormB2 = nn.BatchNorm2d(96)\n",
    "        self.activationB2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.convC1 = nn.Conv2d(256, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnormC1 = nn.BatchNorm2d(64)\n",
    "        self.activationC1 = nn.ReLU(inplace=True)\n",
    "        self.convC2 = nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnormC2 = nn.BatchNorm2d(96)\n",
    "        self.activationC2 = nn.ReLU(inplace=True)\n",
    "        self.convC3 = nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnormC3 = nn.BatchNorm2d(96)\n",
    "        self.activationC3 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.avgpoolD1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.convD1 = nn.Conv2d(256, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnormD1 = nn.BatchNorm2d(64)\n",
    "        self.activationD1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.convA1(x)\n",
    "        out1 = self.batchnormA1(out1)\n",
    "        out1 = self.activationA1(out1)\n",
    "        \n",
    "        out2 = self.convB1(x)\n",
    "        out2 = self.batchnormB1(out2)\n",
    "        out2 = self.activationB1(out2)\n",
    "        out2 = self.convB2(out2)\n",
    "        out2 = self.batchnormB2(out2)\n",
    "        out2 = self.activationB2(out2)\n",
    "        \n",
    "        out3 = self.convC1(x)\n",
    "        out3 = self.batchnormC1(out3)\n",
    "        out3 = self.activationC1(out3)\n",
    "        out3 = self.convC2(out3)\n",
    "        out3 = self.batchnormC2(out3)\n",
    "        out3 = self.activationC2(out3)\n",
    "        out3 = self.convC3(out3)\n",
    "        out3 = self.batchnormC3(out3)\n",
    "        out3 = self.activationC3(out3)\n",
    "        \n",
    "        out4 = self.avgpoolD1(x)\n",
    "        out4 = self.convD1(out4)\n",
    "        out4 = self.batchnormD1(out4)\n",
    "        out4 = self.activationD1(out4)\n",
    "        \n",
    "        out = [out1, out2, out3, out4]\n",
    "        return torch.cat(out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convA1 = nn.Conv2d(320, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnormA1 = nn.BatchNorm2d(64)\n",
    "        self.activationA1 = nn.ReLU(inplace=True)\n",
    "        self.convA2 = nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnormA2 = nn.BatchNorm2d(96)\n",
    "        self.activationA2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.convA1(x)\n",
    "        out = self.batchnormA1(out)\n",
    "        out = self.activationA1(out)\n",
    "        out = self.convA2(out)\n",
    "        out = self.batchnormA2(out)\n",
    "        out = self.activationA2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECO2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.basic_conv = BasicConv()\n",
    "        self.inceptionA = InceptionA()\n",
    "        self.inceptionB = InceptionB()\n",
    "        self.inceptionC = InceptionC()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.basic_conv(x)\n",
    "        x = self.inceptionA(x)\n",
    "        x = self.inceptionB(x)\n",
    "        x = self.inceptionC(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet3dA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convA1 = nn.Conv3d(96, 128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.batchnormB1 = nn.BatchNorm3d(128)\n",
    "        self.activationB1 = nn.ReLU(inplace=True)\n",
    "        self.convB2 = nn.Conv3d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnormB2 = nn.BatchNorm3d(128)\n",
    "        self.activationB2 = nn.ReLU(inplace=True)\n",
    "        self.convB3 = nn.Conv3d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.batchnormC1 = nn.BatchNorm3d(128)\n",
    "        self.activationC1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.convA1(x)\n",
    "        \n",
    "        out = self.batchnormB1(residual)\n",
    "        out = self.activationB1(out)\n",
    "        out = self.convB2(out)\n",
    "        out = self.batchnormB2(out)\n",
    "        out = self.activationB2(out)\n",
    "        out = self.convB3(out)\n",
    "        \n",
    "        out += residual\n",
    "        \n",
    "        out = self.batchnormC1(out)\n",
    "        out = self.activationC1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet3dB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convA1 = nn.Conv3d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.convB1 = nn.Conv3d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.batchnormB1 = nn.BatchNorm3d(256)\n",
    "        self.activationB1 = nn.ReLU(inplace=True)\n",
    "        self.convB2 = nn.Conv3d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.batchnormC1 = nn.BatchNorm3d(256)\n",
    "        self.activationC1 = nn.ReLU(inplace=True)\n",
    "        self.convC2 = nn.Conv3d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnormC2 = nn.BatchNorm3d(256)\n",
    "        self.activationC2 = nn.ReLU(inplace=True)\n",
    "        self.convC3 = nn.Conv3d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.batchnormD1 = nn.BatchNorm3d(256)\n",
    "        self.activationD1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.convA1(x)\n",
    "        \n",
    "        out = self.convB1(x)\n",
    "        out = self.batchnormB1(out)\n",
    "        out = self.activationB1(out)\n",
    "        out = self.convB2(out)\n",
    "        \n",
    "        out += residual\n",
    "        residual = out\n",
    "        \n",
    "        out = self.batchnormC1(out)\n",
    "        out = self.activationC1(out)\n",
    "        out = self.convC2(out)\n",
    "        out = self.batchnormC2(out)\n",
    "        out = self.activationC2(out)\n",
    "        out = self.convC3(out)\n",
    "        \n",
    "        out += residual\n",
    "        \n",
    "        out = self.batchnormD1(out)\n",
    "        out = self.activationD1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet3dC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convA1 = nn.Conv3d(256, 512, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.convB1 = nn.Conv3d(256, 512, kernel_size=3, stride=2, padding=1)\n",
    "        self.batchnormB1 = nn.BatchNorm3d(512)\n",
    "        self.activationB1 = nn.ReLU(inplace=True)\n",
    "        self.convB2 = nn.Conv3d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.batchnormC1 = nn.BatchNorm3d(512)\n",
    "        self.activationC1 = nn.ReLU(inplace=True)\n",
    "        self.convC2 = nn.Conv3d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnormC2 = nn.BatchNorm3d(512)\n",
    "        self.activationC2 = nn.ReLU(inplace=True)\n",
    "        self.convC3 = nn.Conv3d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.batchnormD1 = nn.BatchNorm3d(512)\n",
    "        self.activationD1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.convA1(x)\n",
    "        \n",
    "        out = self.convB1(x)\n",
    "        out = self.batchnormB1(out)\n",
    "        out = self.activationB1(out)\n",
    "        out = self.convB2(out)\n",
    "        \n",
    "        out += residual\n",
    "        residual = out\n",
    "        \n",
    "        out = self.batchnormC1(out)\n",
    "        out = self.activationC1(out)\n",
    "        out = self.convC2(out)\n",
    "        out = self.batchnormC2(out)\n",
    "        out = self.activationC2(out)\n",
    "        out = self.convC3(out)\n",
    "        \n",
    "        out += residual\n",
    "        \n",
    "        out = self.batchnormD1(out)\n",
    "        out = self.activationD1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECO3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet3dA = ResNet3dA()\n",
    "        self.resnet3dB = ResNet3dB()\n",
    "        self.resnet3dC = ResNet3dC()\n",
    "        self.global_pool = nn.AdaptiveAvgPool3d(1)  # Global Average Pooling\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.resnet3dA(x)\n",
    "        x = self.resnet3dB(x)\n",
    "        x = self.resnet3dC(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECO(nn.Module):\n",
    "    def __init__(self, num_label):\n",
    "        super().__init__()\n",
    "        self.eco2d = ECO2d()\n",
    "        self.eco3d = ECO3d()\n",
    "        self.linear = nn.Linear(512, num_label)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, segments, channel, height, width = x.shape\n",
    "        x = x.view(-1, channel, height, width)\n",
    "        x = self.eco2d(x)\n",
    "        x = x.view(-1, segments, 96, 28, 28)\n",
    "        x = self.eco3d(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoTransform():\n",
    "    def __init__(self, resize, crop_size):\n",
    "        self.transform = transforms.Compose([\n",
    "            GroupResize(int(resize)),\n",
    "            GroupCenterCrop(crop_size),\n",
    "            GroupToTensor(),\n",
    "            Stack()\n",
    "        ])\n",
    "        \n",
    "    def  __call__(self, images):\n",
    "        return self.transform(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupResize():\n",
    "    def __init__(self, resize):\n",
    "        self.transform = transforms.Resize(resize)\n",
    "    \n",
    "    def __call__(self, images):\n",
    "        return [self.transform(image) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupCenterCrop():\n",
    "    def __init__(self, crop_size):\n",
    "        self.transform = transforms.CenterCrop(crop_size)\n",
    "    \n",
    "    def __call__(self, images):\n",
    "        return [self.transform(image) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupToTensor():\n",
    "    def __init__(self):\n",
    "        self.transform = transforms.ToTensor()\n",
    "    \n",
    "    def __call__(self, images):\n",
    "        return [self.transform(image) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stack():\n",
    "    def __call__(self, images):\n",
    "        return torch.cat([image.unsqueeze(dim=0) for image in images], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, videos, label2id, num_segments, transform, image_format='image_{:05d}.jpg'):\n",
    "        self.videos = videos\n",
    "        self.label2id = label2id\n",
    "        self.num_segments = num_segments\n",
    "        self.transform = transform\n",
    "        self.image_format = image_format\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.videos[index]\n",
    "        files = os.listdir(path)\n",
    "        tick = len(files) / float(self.num_segments)\n",
    "        indices = np.array([int(tick / 2 + tick * i) for i in range(self.num_segments)]) + 1\n",
    "        images = []\n",
    "        for idx in indices:\n",
    "            file = os.path.join(path, self.image_format.format(idx))\n",
    "            image = Image.open(file).convert('RGB')\n",
    "            images += [image]\n",
    "        label = (path[:-1] if path.endswith('/') else path).split('/')[-2]\n",
    "        label_id = self.label2id[label]\n",
    "        images = self.transform(images)\n",
    "        return images, label, label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meoyoQHI7tAm"
   },
   "outputs": [],
   "source": [
    "class Util:\n",
    "    @staticmethod\n",
    "    def loadImages(batch_size, folder_path, size):\n",
    "        imgs = ImageFolder(folder_path, transform=transforms.Compose([\n",
    "            transforms.Resize(int(size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size),\n",
    "            #transforms.RandomRotation(degrees=30),\n",
    "            #transforms.ColorJitter(brightness=0, contrast=0.5, saturation=0.5),\n",
    "            transforms.ToTensor()\n",
    "        ]))\n",
    "        return DataLoader(imgs, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def showImages(dataloader):\n",
    "        %matplotlib inline\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        PIL = transforms.ToPILImage()\n",
    "        ToTensor = transforms.ToTensor()\n",
    "\n",
    "        for images in dataloader:\n",
    "            for image in images[0]:\n",
    "                img = PIL(image)\n",
    "                fig = plt.figure(dpi=200)\n",
    "                ax = fig.add_subplot(1, 1, 1) # (row, col, num)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                plt.imshow(img)\n",
    "                #plt.gray()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHj4Xny37tAm"
   },
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, use_cpu, epochs, lr, batch_size, resize, crop_size, num_segments, videos, weights_dir):\n",
    "        use_cuda = torch.cuda.is_available() if not use_cpu else False\n",
    "        self.device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(f'Use Device: {self.device}')\n",
    "        \n",
    "        self.num_epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.movie_resize = resize\n",
    "        self.crop_size = crop_size\n",
    "        self.weights_dir = weights_dir\n",
    "        \n",
    "        self.labels = [f for f in os.listdir(videos) if os.path.isdir(os.path.join(videos, f))]\n",
    "        self.label2id = {v:i for i, v in enumerate(self.labels)}\n",
    "        \n",
    "        self.videos = []\n",
    "        for label in self.labels:\n",
    "            path = os.path.join(videos, label)\n",
    "            for file in os.listdir(path):\n",
    "                file = os.path.join(path, file)\n",
    "                if os.path.isdir(file):\n",
    "                    self.videos += [file]\n",
    "        \n",
    "        self.num_label = len(self.labels)\n",
    "        self.num_segments = num_segments\n",
    "        \n",
    "        self.dataset = VideoDataset(self.videos, self.label2id, num_segments,\n",
    "                                    VideoTransform(resize, crop_size))\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        self.net = ECO(self.num_label).to(self.device)\n",
    "        self.state_loaded = False\n",
    "\n",
    "        self.net.apply(self.weights_init)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        \n",
    "        self.epoch = 0\n",
    "    \n",
    "    def weights_init(self, module):\n",
    "        if type(module) == nn.Linear or type(module) == nn.Conv2d or type(module) == nn.ConvTranspose2d:\n",
    "            nn.init.kaiming_normal_(module.weight)\n",
    "            module.bias.data.fill_(0)\n",
    "            \n",
    "    def save_labeldata(self):\n",
    "        with open(os.path.join('.', f'labels.pkl'), 'wb') as f:\n",
    "            dump(self.labels, f)\n",
    "        with open(os.path.join('.', f'label2id.pkl'), 'wb') as f:\n",
    "            dump(self.label2id, f)\n",
    "        print('Saved labeldata.')\n",
    "            \n",
    "    def load_labeldata(self):\n",
    "        if os.path.exists('labels.pkl') and os.path.exists('label2id.pkl'):\n",
    "            with open(os.path.join('.', 'labels.pkl'), 'rb') as f:\n",
    "                print('Load labels.')\n",
    "                self.labels = load(f)\n",
    "            with open(os.path.join('.', 'label2id.pkl'), 'rb') as f:\n",
    "                print('Load label2id.')\n",
    "                self.label2id = load(f)\n",
    "        self.num_label = len(self.labels)\n",
    "            \n",
    "    def save_state(self, epoch):\n",
    "        self.net.cpu()\n",
    "        torch.save(self.net.state_dict(), os.path.join(self.weights_dir, f'weight.{epoch}.pth'))\n",
    "        self.net.to(self.device)\n",
    "        \n",
    "    def load_state(self):\n",
    "        if os.path.exists('weight.pth'):\n",
    "            self.net.load_state_dict(torch.load('weight.pth', map_location=self.device))\n",
    "            self.state_loaded = True\n",
    "            print('Loaded network state.')\n",
    "    \n",
    "    def save_resume(self):\n",
    "        with open(os.path.join('.', f'resume.pkl'), 'wb') as f:\n",
    "            dump(self, f)\n",
    "    \n",
    "    def load_resume(self):\n",
    "        if os.path.exists('resume.pkl'):\n",
    "            with open(os.path.join('.', 'resume.pkl'), 'rb') as f:\n",
    "                print('Load resume.')\n",
    "                return load(f)\n",
    "        else:\n",
    "            return self\n",
    "    \n",
    "    def train(self, resume=True):\n",
    "        self.net.train()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            if epoch < self.epoch:\n",
    "                continue\n",
    "            self.epoch = epoch\n",
    "            \n",
    "            epoch_loss = 0.0\n",
    "            \n",
    "            for iters, (images, label, label_id) in enumerate(tqdm(self.dataloader)):\n",
    "                iters += 1\n",
    "                \n",
    "                images = images.to(self.device)\n",
    "                label_id = label_id.to(self.device)\n",
    "                \n",
    "                out = self.net(images)\n",
    "                loss = criterion(out, label_id)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss\n",
    "                #experiment.log_metric('Loss', loss)\n",
    "                \n",
    "            self.save_state(epoch)\n",
    "            print(f'Epoch[{self.epoch}] Loss[{epoch_loss}]')\n",
    "                    \n",
    "            if resume:\n",
    "                self.save_resume()\n",
    "    \n",
    "    def validate(self):\n",
    "        self.net.eval()\n",
    "        \n",
    "        valid = []\n",
    "        for iters, (images, label, label_id) in enumerate(tqdm(self.dataloader)):\n",
    "            images = images.to(self.device)\n",
    "            out = self.net(images)\n",
    "            \n",
    "            pred_label = np.argmax(out.cpu().detach().numpy(), axis=1)\n",
    "            label_id = label_id.detach().numpy()\n",
    "            \n",
    "            precision = precision_score(label_id, pred_label, average='macro', zero_division=1)\n",
    "            recall = recall_score(label_id, pred_label, average='macro', zero_division=1)\n",
    "            f1 = f1_score(label_id, pred_label, average='macro', zero_division=1)\n",
    "            valid += [[precision, recall, f1]]\n",
    "            \n",
    "        valid = np.mean(valid, axis=0)\n",
    "        print(f'Precision: {valid[0]}')\n",
    "        print(f'Recall: {valid[1]}')\n",
    "        print(f'F1: {valid[2]}')\n",
    "    \n",
    "    def predict(self, file):\n",
    "        self.net.eval()\n",
    "        \n",
    "        name, ext = os.path.splitext(file)\n",
    "        if not os.path.exists(name):\n",
    "            os.mkdir(name)\n",
    "        command = f'ffmpeg -i \\\"{file}\\\" -vf scale=-1:256 \\\"{name}/image_%05d.jpg\\\"'\n",
    "        print(command)\n",
    "        subprocess.call(command, shell=True)\n",
    "        print('Converted data.')\n",
    "        \n",
    "        files = os.listdir(name)\n",
    "        tick = len(files) / float(self.num_segments)\n",
    "        indices = np.array([int(tick / 2 + tick * i) for i in range(self.num_segments)]) + 1\n",
    "        images = []\n",
    "        for idx in indices:\n",
    "            file = os.path.join(name, f'image_{idx:05d}.jpg')\n",
    "            image = Image.open(file).convert('RGB')\n",
    "            images += [image]\n",
    "        images = VideoTransform(self.movie_resize, self.crop_size)(images).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        pred = F.softmax(self.net(images), dim=1).cpu().detach().numpy()[0]\n",
    "        indexes = np.argsort(pred)[::-1]\n",
    "        print('Predicted:')\n",
    "        for i in indexes:\n",
    "            print(f'\\t{self.labels[i]}: {pred[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OC8jOA2N7tAp"
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    hyper_params = {}\n",
    "    hyper_params['Videos Dir'] = args.videos\n",
    "    hyper_params['Weights Dir'] = args.weights_dir\n",
    "    hyper_params['Data Resize'] = args.resize\n",
    "    hyper_params['Data Crop Size'] = args.crop_size\n",
    "    hyper_params['Num Segments'] = args.num_segments\n",
    "    hyper_params['Learning Rate'] = args.lr\n",
    "    hyper_params['Batch Size'] = args.batch_size\n",
    "    hyper_params['Epochs'] = args.epochs\n",
    "    \n",
    "    solver = Solver(args.cpu, args.epochs, args.lr, args.batch_size,\n",
    "                    args.resize, args.crop_size, args.num_segments, args.videos, args.weights_dir)\n",
    "    solver.load_state()\n",
    "    solver.load_labeldata()\n",
    "    \n",
    "    if not args.noresume:\n",
    "        solver = solver.load_resume()\n",
    "    \n",
    "    if args.predict:\n",
    "        solver.load_labeldata()\n",
    "        solver.predict(args.predict)\n",
    "        return\n",
    "    \n",
    "    for key in hyper_params.keys():\n",
    "        print(f'{key}: {hyper_params[key]}')\n",
    "    #experiment.log_parameters(hyper_params)\n",
    "    \n",
    "    if args.validate:\n",
    "        solver.validate()\n",
    "        return\n",
    "    \n",
    "    solver.save_labeldata()\n",
    "    solver.train(not args.noresume)\n",
    "    #experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2njRAfXr7tAp"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--videos', type=str, default='')\n",
    "    parser.add_argument('--weights_dir', type=str, default='weights')\n",
    "    parser.add_argument('--resize', type=int, default=224)\n",
    "    parser.add_argument('--crop_size', type=int, default=224)\n",
    "    parser.add_argument('--num_segments', type=int, default=16)\n",
    "    parser.add_argument('--lr', type=float, default=0.0001)\n",
    "    parser.add_argument('--batch_size', type=int, default=8)\n",
    "    parser.add_argument('--epochs', type=int, default=100)\n",
    "    parser.add_argument('--cpu', action='store_true')\n",
    "    parser.add_argument('--noresume', action='store_true')\n",
    "    parser.add_argument('--predict', type=str, default='')\n",
    "    parser.add_argument('--validate', action='store_true')\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    \n",
    "    if not os.path.exists(args.weights_dir):\n",
    "        os.mkdir(args.weights_dir)\n",
    "    \n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "StyleGAN1.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
